{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf65050",
   "metadata": {
    "gather": {
     "logged": 1702338448005
    },
    "id": "5bf65050"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ae0214-f88c-464f-bcb5-53c967fda5c1",
   "metadata": {
    "gather": {
     "logged": 1702338454975
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d32934",
   "metadata": {
    "gather": {
     "logged": 1702338461386
    },
    "id": "33d32934"
   },
   "outputs": [],
   "source": [
    "data_x=pd.read_csv(\"F:\\Personal\\Queens MMAI\\MMAI 869 – Machine Learning and AI Technology\\Driven Data team Assignment\\Train set values.csv\")\n",
    "data_y=pd.read_csv(\"F:\\Personal\\Queens MMAI\\MMAI 869 – Machine Learning and AI Technology\\Driven Data team Assignment\\Train set labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f4a384",
   "metadata": {
    "gather": {
     "logged": 1702338461729
    },
    "id": "44f4a384"
   },
   "outputs": [],
   "source": [
    "data=pd.merge(data_x,data_y,on=\"id\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e5b7",
   "metadata": {
    "id": "8dc5e5b7"
   },
   "source": [
    "## Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a687ee0d",
   "metadata": {
    "gather": {
     "logged": 1702338464914
    },
    "id": "a687ee0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(data_x,data_y,train_size=0.7,random_state=42,stratify=data_y[\"status_group\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603fccf",
   "metadata": {
    "id": "9603fccf"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba2aa2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "gather": {
     "logged": 1702338465289
    },
    "id": "6ba2aa2e",
    "outputId": "c50241b6-d8e6-40bd-89cb-9d21d4a75db4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>4.158000e+04</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "      <td>41580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37053.095238</td>\n",
       "      <td>328.297768</td>\n",
       "      <td>670.883333</td>\n",
       "      <td>34.088923</td>\n",
       "      <td>-5.716324e+00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>15.198509</td>\n",
       "      <td>5.593218</td>\n",
       "      <td>180.270178</td>\n",
       "      <td>1303.064791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21379.253543</td>\n",
       "      <td>3380.560532</td>\n",
       "      <td>693.624472</td>\n",
       "      <td>6.541418</td>\n",
       "      <td>2.940352e+00</td>\n",
       "      <td>14.103926</td>\n",
       "      <td>17.463795</td>\n",
       "      <td>9.575067</td>\n",
       "      <td>462.724333</td>\n",
       "      <td>950.851187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18530.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.097738</td>\n",
       "      <td>-8.543252e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37055.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.000000</td>\n",
       "      <td>34.911885</td>\n",
       "      <td>-5.036156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55351.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1322.000000</td>\n",
       "      <td>37.169114</td>\n",
       "      <td>-3.328690e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.344301</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>15300.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  41580.000000   41580.000000  41580.000000  41580.000000  4.158000e+04   \n",
       "mean   37053.095238     328.297768    670.883333     34.088923 -5.716324e+00   \n",
       "std    21379.253543    3380.560532    693.624472      6.541418  2.940352e+00   \n",
       "min        0.000000       0.000000    -63.000000      0.000000 -1.164944e+01   \n",
       "25%    18530.750000       0.000000      0.000000     33.097738 -8.543252e+00   \n",
       "50%    37055.500000       0.000000    374.000000     34.911885 -5.036156e+00   \n",
       "75%    55351.250000      25.000000   1322.000000     37.169114 -3.328690e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.344301 -2.000000e-08   \n",
       "\n",
       "        num_private   region_code  district_code    population  \\\n",
       "count  41580.000000  41580.000000   41580.000000  41580.000000   \n",
       "mean       0.500000     15.198509       5.593218    180.270178   \n",
       "std       14.103926     17.463795       9.575067    462.724333   \n",
       "min        0.000000      1.000000       0.000000      0.000000   \n",
       "25%        0.000000      5.000000       2.000000      0.000000   \n",
       "50%        0.000000     12.000000       3.000000     27.500000   \n",
       "75%        0.000000     17.000000       5.000000    215.000000   \n",
       "max     1776.000000     99.000000      80.000000  15300.000000   \n",
       "\n",
       "       construction_year  \n",
       "count       41580.000000  \n",
       "mean         1303.064791  \n",
       "std           950.851187  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%          1986.000000  \n",
       "75%          2004.000000  \n",
       "max          2013.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numerical Features Description\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3845f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "gather": {
     "logged": 1702338465630
    },
    "id": "2a3845f3",
    "outputId": "35658fc5-37ac-46b4-af15-6e56c5afdd64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41580</td>\n",
       "      <td>39034</td>\n",
       "      <td>39025</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41336</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>39283</td>\n",
       "      <td>...</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "      <td>41580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>346</td>\n",
       "      <td>1611</td>\n",
       "      <td>1802</td>\n",
       "      <td>27265</td>\n",
       "      <td>9</td>\n",
       "      <td>16078</td>\n",
       "      <td>21</td>\n",
       "      <td>124</td>\n",
       "      <td>2073</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2011-03-17</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>DWE</td>\n",
       "      <td>none</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>Njombe</td>\n",
       "      <td>Igosi</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>410</td>\n",
       "      <td>6405</td>\n",
       "      <td>12204</td>\n",
       "      <td>2546</td>\n",
       "      <td>7058</td>\n",
       "      <td>364</td>\n",
       "      <td>3752</td>\n",
       "      <td>1769</td>\n",
       "      <td>222</td>\n",
       "      <td>35748</td>\n",
       "      <td>...</td>\n",
       "      <td>17792</td>\n",
       "      <td>35496</td>\n",
       "      <td>35496</td>\n",
       "      <td>23232</td>\n",
       "      <td>23232</td>\n",
       "      <td>11944</td>\n",
       "      <td>11944</td>\n",
       "      <td>32085</td>\n",
       "      <td>19911</td>\n",
       "      <td>24183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_recorded                  funder installer wpt_name  \\\n",
       "count          41580                   39034     39025    41580   \n",
       "unique           346                    1611      1802    27265   \n",
       "top       2011-03-17  Government Of Tanzania       DWE     none   \n",
       "freq             410                    6405     12204     2546   \n",
       "\n",
       "                basin subvillage  region     lga   ward public_meeting  ...  \\\n",
       "count           41580      41336   41580   41580  41580          39283  ...   \n",
       "unique              9      16078      21     124   2073              2  ...   \n",
       "top     Lake Victoria    Majengo  Iringa  Njombe  Igosi           True  ...   \n",
       "freq             7058        364    3752    1769    222          35748  ...   \n",
       "\n",
       "       payment_type water_quality quality_group quantity quantity_group  \\\n",
       "count         41580         41580         41580    41580          41580   \n",
       "unique            7             8             6        5              5   \n",
       "top       never pay          soft          good   enough         enough   \n",
       "freq          17792         35496         35496    23232          23232   \n",
       "\n",
       "        source source_type source_class     waterpoint_type  \\\n",
       "count    41580       41580        41580               41580   \n",
       "unique      10           7            3                   7   \n",
       "top     spring      spring  groundwater  communal standpipe   \n",
       "freq     11944       11944        32085               19911   \n",
       "\n",
       "       waterpoint_type_group  \n",
       "count                  41580  \n",
       "unique                     6  \n",
       "top       communal standpipe  \n",
       "freq                   24183  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical Features Description\n",
    "x_train.describe(include=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ede26d",
   "metadata": {
    "gather": {
     "logged": 1702338465969
    },
    "id": "83ede26d",
    "outputId": "59337eda-5ce0-4f99-f01f-d1745f9d5eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2073"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ward.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821287ae",
   "metadata": {
    "id": "821287ae"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f66626",
   "metadata": {
    "gather": {
     "logged": 1702338466322
    },
    "id": "46f66626"
   },
   "outputs": [],
   "source": [
    "# making a copy of x_train and y_train. All processing will be done on the copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716e78bd",
   "metadata": {
    "gather": {
     "logged": 1702338466608
    },
    "id": "716e78bd"
   },
   "outputs": [],
   "source": [
    "x_train_3=x_train.copy()\n",
    "y_train_3=y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c1e363",
   "metadata": {
    "gather": {
     "logged": 1702338466958
    },
    "id": "90c1e363"
   },
   "outputs": [],
   "source": [
    "def process2(a,b):\n",
    "    ## new feature processing\n",
    "    for i in [\"funder\",\"installer\"]:\n",
    "        a[i]=a[i].str.lower()\n",
    "        minor_values=a[i].value_counts(dropna=False)[a[i].value_counts(dropna=False,normalize=True).cumsum().values>0.95].index\n",
    "        a[i]=a[i].apply(lambda s:\"minor\" if s in minor_values else s)\n",
    "        grp_mode=a.groupby(by=[\"region\"])[i].transform(lambda x: x.mode().iloc[0])\n",
    "        a[i]=a[i].fillna(grp_mode)\n",
    "    a[\"long_mod\"]=a[\"longitude\"]\n",
    "    a.loc[a['long_mod'] == 0, 'long_mod'] = pd.NA\n",
    "    grp_means=a.groupby(by=[\"region\"])[\"long_mod\"].transform(\"mean\")\n",
    "    a.long_mod=a.long_mod.fillna(grp_means)\n",
    "    a[\"lat_mod\"]=a[\"latitude\"]\n",
    "    a.loc[a['lat_mod'] <-100, 'lat_mod'] = pd.NA\n",
    "    grp_means2=a.groupby(by=[\"region\"])[\"lat_mod\"].transform(\"mean\")\n",
    "    a.lat_mod=a.lat_mod.fillna(grp_means2)\n",
    "    a[\"gps_height_mod\"]=a[\"gps_height\"]\n",
    "    a.loc[a['gps_height_mod'] == 0, 'gps_height_mod'] = pd.NA\n",
    "    grp_means3=a.groupby(by=[\"basin\"])[\"gps_height_mod\"].transform(\"mean\")\n",
    "    a.gps_height_mod=a.gps_height_mod.fillna(grp_means3)\n",
    "    a.wpt_name=a.wpt_name.str.lower()\n",
    "    x=list(a.wpt_name.value_counts()[(a.wpt_name.value_counts().values==1)].index)\n",
    "    a.wpt_name=a.wpt_name.replace(x,\"single\")\n",
    "    #subvillage\n",
    "    grp_mode4=a.groupby(by=[\"region\"])[\"subvillage\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.subvillage=a.subvillage.fillna(grp_mode4)\n",
    "    y=list(a.subvillage.value_counts()[(a.subvillage.value_counts().values==1)].index)\n",
    "    a.subvillage=a.subvillage.replace(y,\"single\")\n",
    "    a.public_meeting=a.public_meeting.fillna(\"True\")\n",
    "    grp_mode5=a.groupby(by=[\"region\"])[\"permit\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.permit=a.permit.fillna(grp_mode5)\n",
    "    grp_mode6=a.groupby(by=[\"region\"])[\"scheme_management\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.scheme_management=a.scheme_management.fillna(grp_mode6)\n",
    "    a[\"permit\"]=a[\"permit\"].map(lambda s: \"T\" if s==True else(\"F\" if s== False else \"M\"))\n",
    "    a[\"public_meeting\"]=a[\"public_meeting\"].map(lambda s: \"T\" if s==True else(\"F\" if s== False else \"M\"))\n",
    "    #bin_edges=[np.min(a.gps_height)-1,0,500,1000,1500,2000,np.max(a.gps_height)]\n",
    "    #bin_labels=[\"<0\",\"0-500\",\"500-1000\",\"1000-1500\",\"1500-2000\",\">2000\"]\n",
    "    #a[\"gps_height_cat\"]=pd.cut(a.gps_height,bins=bin_edges,labels=bin_labels).astype(\"O\")\n",
    "    a=a.drop([\"id\",\"recorded_by\",\"scheme_name\",\"num_private\"],axis=1)\n",
    "    b=b.drop(\"id\",axis=1)\n",
    "    a[\"amount_tsh_cat\"] = a[\"amount_tsh\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "    date_format = '%Y-%m-%d'\n",
    "    a[\"date_recorded\"]=pd.to_datetime(a[\"date_recorded\"])\n",
    "    a[\"dsr\"]=pd.to_datetime(\"2023-11-16\")-a[\"date_recorded\"]\n",
    "    a.dsr=(a.dsr/ pd.Timedelta(seconds=86400))\n",
    "    bin_edges=[np.min(a.construction_year)-1,0,1961,1971,1981,1991,2001,np.max(a.construction_year)+1]\n",
    "    bin_labels=[\"0\",\"0-1960\",\"1960-70\",\"1970-80\",\"1980-90\",\"1990-2000\",\"2001-2013\"]\n",
    "    a[\"construction_year_cat\"]=pd.cut(a.construction_year,bins=bin_edges,labels=bin_labels).astype(\"O\")\n",
    "    a=a.drop([\"amount_tsh\",\"date_recorded\",\"gps_height\",\"latitude\",\"longitude\",\"construction_year\"],axis=1)\n",
    "    a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]]=a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]].astype(\"O\")\n",
    "    cat=a.select_dtypes(include=\"O\").columns\n",
    "    #a[cat] = a[cat].fillna('missing')\n",
    "    a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]]=a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]].astype(\"O\")\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce36b4c",
   "metadata": {
    "gather": {
     "logged": 1702338518069
    },
    "id": "cce36b4c"
   },
   "outputs": [],
   "source": [
    "x_train_2,y_train_2=process2(x_train_3,y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d60f90d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1702338518442
    },
    "id": "3d60f90d",
    "outputId": "5b59e126-1a6e-480a-b8df-7f0974ec6431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       41580\n",
       "amount_tsh                  93\n",
       "date_recorded              346\n",
       "funder                    1611\n",
       "gps_height                2385\n",
       "installer                 1802\n",
       "longitude                40285\n",
       "latitude                 40283\n",
       "wpt_name                 27265\n",
       "num_private                 58\n",
       "basin                        9\n",
       "subvillage               16078\n",
       "region                      21\n",
       "region_code                 27\n",
       "district_code               20\n",
       "lga                        124\n",
       "ward                      2073\n",
       "population                 948\n",
       "public_meeting               2\n",
       "recorded_by                  1\n",
       "scheme_management           12\n",
       "scheme_name               2472\n",
       "permit                       2\n",
       "construction_year           55\n",
       "extraction_type             18\n",
       "extraction_type_group       13\n",
       "extraction_type_class        7\n",
       "management                  12\n",
       "management_group             5\n",
       "payment                      7\n",
       "payment_type                 7\n",
       "water_quality                8\n",
       "quality_group                6\n",
       "quantity                     5\n",
       "quantity_group               5\n",
       "source                      10\n",
       "source_type                  7\n",
       "source_class                 3\n",
       "waterpoint_type              7\n",
       "waterpoint_type_group        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e73e401",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1702338518833
    },
    "id": "0e73e401",
    "outputId": "287074a7-d151-4b40-c814-15c7de502fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funder                   0\n",
       "installer                0\n",
       "wpt_name                 0\n",
       "basin                    0\n",
       "subvillage               0\n",
       "region                   0\n",
       "region_code              0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "scheme_management        0\n",
       "permit                   0\n",
       "extraction_type          0\n",
       "extraction_type_group    0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "management_group         0\n",
       "payment                  0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quality_group            0\n",
       "quantity                 0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "source_type              0\n",
       "source_class             0\n",
       "waterpoint_type          0\n",
       "waterpoint_type_group    0\n",
       "long_mod                 0\n",
       "lat_mod                  0\n",
       "gps_height_mod           0\n",
       "amount_tsh_cat           0\n",
       "dsr                      0\n",
       "construction_year_cat    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22438f39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1702338519276
    },
    "id": "22438f39",
    "outputId": "f47f11a9-5ba8-470a-9123-81237a516447"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['funder', 'installer', 'wpt_name', 'basin', 'subvillage', 'region',\n",
       "       'region_code', 'district_code', 'lga', 'ward', 'population',\n",
       "       'public_meeting', 'scheme_management', 'permit', 'extraction_type',\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group', 'long_mod',\n",
       "       'lat_mod', 'gps_height_mod', 'amount_tsh_cat', 'dsr',\n",
       "       'construction_year_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b35c5e",
   "metadata": {
    "gather": {
     "logged": 1702338531178
    },
    "id": "20b35c5e"
   },
   "outputs": [],
   "source": [
    "x_test_2=x_test.copy()\n",
    "y_test_2=y_test.copy()\n",
    "x_test_2,y_test_2=process2(x_test_2,y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "H8Lc1JXkBXwc",
   "metadata": {
    "gather": {
     "logged": 1702338531810
    },
    "id": "H8Lc1JXkBXwc"
   },
   "outputs": [],
   "source": [
    "## Categorical features encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "Label_col=x_train_2.select_dtypes(include=\"O\").columns\n",
    "Or=OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "Or.fit(x_train_2[Label_col])\n",
    "x_train_2[Label_col]=Or.transform(x_train_2[Label_col])\n",
    "x_test_2[Label_col]=Or.transform(x_test_2[Label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sgAUZGYsBc6o",
   "metadata": {
    "gather": {
     "logged": 1702338532130
    },
    "id": "sgAUZGYsBc6o"
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(y_train_2[\"status_group\"])\n",
    "y_train_2[\"status_group\"]=le.transform(y_train_2[\"status_group\"])\n",
    "y_test_2[\"status_group\"]=le.transform(y_test_2[\"status_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6737d5c6",
   "metadata": {
    "gather": {
     "logged": 1702225141281
    },
    "id": "6737d5c6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "def matrix(xtr,ytr,xte,yte,est):\n",
    "    print (\"\\n Train accuracy\",round(accuracy_score(ytr, est.predict(xtr)),3))\n",
    "    print (\"\\n Train Classification Report\\n\\n\", classification_report(ytr, est.predict(xtr)))\n",
    "    print (\"\\n Test accuracy\", round(accuracy_score(yte, est.predict(xte)),3))\n",
    "    print (\"\\n Test Classification Report\\n\\n\", classification_report(yte, est.predict(xte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d317eb",
   "metadata": {
    "gather": {
     "logged": 1702338536852
    },
    "id": "f9d317eb"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5692729c",
   "metadata": {
    "gather": {
     "logged": 1702338537188
    },
    "id": "5692729c"
   },
   "outputs": [],
   "source": [
    "cat_col=list(x_train_2.select_dtypes(include=\"O\").columns)\n",
    "#clf = CatBoostClassifier(iterations=10, depth=5, learning_rate=0.1, loss_function='MultiClass',cat_features=cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd563a77",
   "metadata": {
    "gather": {
     "logged": 1702338537497
    },
    "id": "cd563a77"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2178ce6c",
   "metadata": {
    "gather": {
     "logged": 1702338537809
    },
    "id": "2178ce6c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b1c03dd",
   "metadata": {
    "gather": {
     "logged": 1702338538148
    },
    "id": "9b1c03dd",
    "outputId": "a4c03c15-553f-4cef-8d99-e99959b298f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27800</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39725</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21108</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14847</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26579</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49783</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41580 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status_group\n",
       "5974              0\n",
       "31787             0\n",
       "27800             0\n",
       "8008              2\n",
       "39725             2\n",
       "...             ...\n",
       "21108             1\n",
       "14847             2\n",
       "26579             2\n",
       "8192              0\n",
       "49783             0\n",
       "\n",
       "[41580 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3a401",
   "metadata": {
    "id": "4cf3a401"
   },
   "outputs": [],
   "source": [
    "#cat_col=list(x_train_2.select_dtypes(include=\"O\").columns)\n",
    "#clf = CatBoostClassifier(loss_function='MultiClass',cat_features=cat_col)\n",
    "#parameters={\"iterations\":[1000],\"depth\":np.arange(2,20,2),\"learning_rate\":np.arange(0.01,0.1,0.01),\"max_bin\":np.arange(10,100,5)}\n",
    "#Grid=GridSearchCV(clf,param_grid=parameters,cv=5,scoring=\"f1_macro\",n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1089394f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1702338540181
    },
    "id": "1089394f",
    "outputId": "f5c52c77-7510-42c6-faf0-5d5aec574d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (3.4.0)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: colorlog in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (6.8.0)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: PyYAML in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (1.13.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (2.0.23)\n",
      "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: Mako in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.12.0)\n",
      "Requirement already satisfied: importlib-metadata in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Mh4OYtpN_q_n",
   "metadata": {
    "gather": {
     "logged": 1702339226110
    },
    "id": "Mh4OYtpN_q_n"
   },
   "outputs": [],
   "source": [
    "def objective_dt(trial, X, y):\n",
    "\n",
    "  # Now, define all the hyperparams we want to vary, and what values they are allowed\n",
    "  # to take.\n",
    "  #\n",
    "  # Each trial, optuna will automatically choose values for each hyperparam.\n",
    "  hyper_params = {\n",
    "        \"objective\":'multiclass',\n",
    "        \"n_estimators\":1000,\n",
    "       #\"max_depth\":trial.suggest_int(\"max_depth\",8,16,step=2),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\",0.01,.19,step=.01),\n",
    "        \"max_bin\":trial.suggest_int(\"max_bin\",40,200,step=10),\n",
    "        \"random_state\": 60,\n",
    "  }\n",
    "\n",
    "\n",
    "  # Use the hyperparams that optuna has chosen for this trial to create a DecisionTreeClassifier\n",
    "  clf_lgbm = LGBMClassifier(**hyper_params)\n",
    "\n",
    "  # Run CV to see how well these hyper_params do\n",
    "  cv_scores = cross_val_score(clf_lgbm, X, y, cv=5, scoring=\"f1_macro\")\n",
    "  score = np.mean(cv_scores)\n",
    "\n",
    "  # Whatever we return here tells optuna how well these parameters did\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lP-c0_4DAJkT",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1702344647696
    },
    "id": "lP-c0_4DAJkT",
    "outputId": "5f6d64b3-4dde-4930-9a58-7884bad91dce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-12 00:00:28,456] A new study created in memory with name: no-name-9289cc79-de4b-47c3-8e8e-a0deb119e9b1\n",
      "[I 2023-12-12 00:01:17,998] Trial 0 finished with value: 0.6741637575696631 and parameters: {'learning_rate': 0.11, 'max_bin': 70}. Best is trial 0 with value: 0.6741637575696631.\n",
      "[I 2023-12-12 00:02:01,738] Trial 1 finished with value: 0.6740734162167262 and parameters: {'learning_rate': 0.14, 'max_bin': 50}. Best is trial 0 with value: 0.6741637575696631.\n",
      "[I 2023-12-12 00:02:58,654] Trial 2 finished with value: 0.6800998301570155 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 120}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:03:51,516] Trial 3 finished with value: 0.6765970467432411 and parameters: {'learning_rate': 0.12, 'max_bin': 130}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:05:04,714] Trial 4 finished with value: 0.6494601157199713 and parameters: {'learning_rate': 0.01, 'max_bin': 190}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:06:01,950] Trial 5 finished with value: 0.6770781905562321 and parameters: {'learning_rate': 0.04, 'max_bin': 60}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:06:54,146] Trial 6 finished with value: 0.6772514126037015 and parameters: {'learning_rate': 0.11, 'max_bin': 120}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:08:01,906] Trial 7 finished with value: 0.6504022330329561 and parameters: {'learning_rate': 0.01, 'max_bin': 160}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:08:49,785] Trial 8 finished with value: 0.670276055975156 and parameters: {'learning_rate': 0.14, 'max_bin': 40}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:09:50,815] Trial 9 finished with value: 0.6632851894692383 and parameters: {'learning_rate': 0.02, 'max_bin': 100}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:10:44,511] Trial 10 finished with value: 0.6739425369392313 and parameters: {'learning_rate': 0.19, 'max_bin': 200}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:11:38,696] Trial 11 finished with value: 0.6784810562187824 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 120}. Best is trial 2 with value: 0.6800998301570155.\n",
      "[I 2023-12-12 00:12:32,292] Trial 12 finished with value: 0.680736731059216 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:13:31,008] Trial 13 finished with value: 0.6763943475449352 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:14:24,564] Trial 14 finished with value: 0.6793714943712181 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 90}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:15:20,362] Trial 15 finished with value: 0.6779310754365104 and parameters: {'learning_rate': 0.08, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:16:13,710] Trial 16 finished with value: 0.6774875542191252 and parameters: {'learning_rate': 0.04, 'max_bin': 90}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:17:08,802] Trial 17 finished with value: 0.6789100457678255 and parameters: {'learning_rate': 0.09, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:18:01,724] Trial 18 finished with value: 0.6754796162132991 and parameters: {'learning_rate': 0.18000000000000002, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:18:52,635] Trial 19 finished with value: 0.674863493138872 and parameters: {'learning_rate': 0.14, 'max_bin': 110}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:19:48,829] Trial 20 finished with value: 0.6776966833225797 and parameters: {'learning_rate': 0.05, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:20:40,606] Trial 21 finished with value: 0.6755958583193237 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 80}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:21:31,431] Trial 22 finished with value: 0.678412824427349 and parameters: {'learning_rate': 0.09, 'max_bin': 100}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:22:25,890] Trial 23 finished with value: 0.6777820448911671 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:23:17,506] Trial 24 finished with value: 0.6755958583193237 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 80}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:24:13,349] Trial 25 finished with value: 0.6707031267464861 and parameters: {'learning_rate': 0.03, 'max_bin': 110}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:25:04,993] Trial 26 finished with value: 0.6765970467432411 and parameters: {'learning_rate': 0.12, 'max_bin': 130}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:25:57,932] Trial 27 finished with value: 0.678412824427349 and parameters: {'learning_rate': 0.09, 'max_bin': 100}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:26:51,339] Trial 28 finished with value: 0.680736731059216 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:27:44,939] Trial 29 finished with value: 0.6742421263062377 and parameters: {'learning_rate': 0.16, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:28:36,572] Trial 30 finished with value: 0.6763430820552024 and parameters: {'learning_rate': 0.11, 'max_bin': 130}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:29:26,331] Trial 31 finished with value: 0.677416096263538 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 70}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:30:22,742] Trial 32 finished with value: 0.6766996957838245 and parameters: {'learning_rate': 0.08, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:31:15,718] Trial 33 finished with value: 0.6766511506994761 and parameters: {'learning_rate': 0.05, 'max_bin': 110}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:32:10,561] Trial 34 finished with value: 0.6786361331306395 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:33:04,786] Trial 35 finished with value: 0.6777445373780784 and parameters: {'learning_rate': 0.08, 'max_bin': 130}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:33:55,217] Trial 36 finished with value: 0.676875146565949 and parameters: {'learning_rate': 0.12, 'max_bin': 120}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:34:51,433] Trial 37 finished with value: 0.6767312821072842 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:35:42,652] Trial 38 finished with value: 0.671904791109361 and parameters: {'learning_rate': 0.04, 'max_bin': 50}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:36:31,914] Trial 39 finished with value: 0.6745078514799054 and parameters: {'learning_rate': 0.13, 'max_bin': 80}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:37:25,740] Trial 40 finished with value: 0.6763566601896047 and parameters: {'learning_rate': 0.05, 'max_bin': 120}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:38:17,957] Trial 41 finished with value: 0.6789100457678255 and parameters: {'learning_rate': 0.09, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:39:11,152] Trial 42 finished with value: 0.6767208826315051 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:40:04,083] Trial 43 finished with value: 0.6766996957838245 and parameters: {'learning_rate': 0.08, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:40:57,505] Trial 44 finished with value: 0.6786096353522374 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:41:51,061] Trial 45 finished with value: 0.6794127796565673 and parameters: {'learning_rate': 0.09, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:42:47,330] Trial 46 finished with value: 0.6764639918655377 and parameters: {'learning_rate': 0.11, 'max_bin': 200}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:43:42,362] Trial 47 finished with value: 0.6790576734085458 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:44:40,992] Trial 48 finished with value: 0.6699387079159699 and parameters: {'learning_rate': 0.03, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:45:35,646] Trial 49 finished with value: 0.6763494310478385 and parameters: {'learning_rate': 0.09, 'max_bin': 190}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:46:26,860] Trial 50 finished with value: 0.678429669479188 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 90}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:47:23,329] Trial 51 finished with value: 0.6749462298266097 and parameters: {'learning_rate': 0.08, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:48:18,333] Trial 52 finished with value: 0.6790576734085458 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:49:13,815] Trial 53 finished with value: 0.6777547207421588 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 190}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:50:09,618] Trial 54 finished with value: 0.6758565316953694 and parameters: {'learning_rate': 0.05, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:51:07,013] Trial 55 finished with value: 0.6767312821072842 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:52:01,509] Trial 56 finished with value: 0.6785402470776483 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 200}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:52:56,392] Trial 57 finished with value: 0.6773810659151194 and parameters: {'learning_rate': 0.11, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:53:49,018] Trial 58 finished with value: 0.6777445373780784 and parameters: {'learning_rate': 0.08, 'max_bin': 130}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:54:45,404] Trial 59 finished with value: 0.6767761144687564 and parameters: {'learning_rate': 0.04, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:55:39,244] Trial 60 finished with value: 0.678412824427349 and parameters: {'learning_rate': 0.09, 'max_bin': 100}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:56:36,358] Trial 61 finished with value: 0.6790576734085458 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:57:32,395] Trial 62 finished with value: 0.6759554834827308 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 190}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:58:27,597] Trial 63 finished with value: 0.6790576734085458 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 00:59:22,335] Trial 64 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:00:16,562] Trial 65 finished with value: 0.6789213438055536 and parameters: {'learning_rate': 0.08, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:01:08,824] Trial 66 finished with value: 0.6762993478349622 and parameters: {'learning_rate': 0.09, 'max_bin': 110}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:01:58,113] Trial 67 finished with value: 0.6758350060783844 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 60}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:02:50,520] Trial 68 finished with value: 0.6751093188126421 and parameters: {'learning_rate': 0.05, 'max_bin': 90}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:03:42,663] Trial 69 finished with value: 0.6780488751482296 and parameters: {'learning_rate': 0.08, 'max_bin': 120}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:04:35,017] Trial 70 finished with value: 0.6775398982322658 and parameters: {'learning_rate': 0.13, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:05:29,491] Trial 71 finished with value: 0.6777547207421588 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 190}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:06:22,104] Trial 72 finished with value: 0.6771110277553017 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:07:14,658] Trial 73 finished with value: 0.6800067267525265 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:08:05,766] Trial 74 finished with value: 0.676901526108157 and parameters: {'learning_rate': 0.09, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:09:01,086] Trial 75 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:09:54,003] Trial 76 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:10:46,629] Trial 77 finished with value: 0.677775717426617 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:11:40,585] Trial 78 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:12:33,897] Trial 79 finished with value: 0.6766996957838245 and parameters: {'learning_rate': 0.08, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:13:30,644] Trial 80 finished with value: 0.6783162708191413 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:14:23,317] Trial 81 finished with value: 0.6794127796565673 and parameters: {'learning_rate': 0.09, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:15:18,070] Trial 82 finished with value: 0.6789213438055536 and parameters: {'learning_rate': 0.08, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:16:12,780] Trial 83 finished with value: 0.6793702807303116 and parameters: {'learning_rate': 0.09, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:17:09,016] Trial 84 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:18:02,595] Trial 85 finished with value: 0.6786096353522374 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:18:55,470] Trial 86 finished with value: 0.6777445373780784 and parameters: {'learning_rate': 0.08, 'max_bin': 130}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:19:49,294] Trial 87 finished with value: 0.6757300523056953 and parameters: {'learning_rate': 0.11, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:20:44,158] Trial 88 finished with value: 0.6749462298266097 and parameters: {'learning_rate': 0.08, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:21:40,164] Trial 89 finished with value: 0.6786096353522374 and parameters: {'learning_rate': 0.06999999999999999, 'max_bin': 150}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:22:36,311] Trial 90 finished with value: 0.6759554834827308 and parameters: {'learning_rate': 0.060000000000000005, 'max_bin': 190}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:23:29,911] Trial 91 finished with value: 0.677775717426617 and parameters: {'learning_rate': 0.09999999999999999, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:24:23,503] Trial 92 finished with value: 0.6793702807303116 and parameters: {'learning_rate': 0.09, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:25:20,221] Trial 93 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:26:16,353] Trial 94 finished with value: 0.680137867425094 and parameters: {'learning_rate': 0.08, 'max_bin': 170}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:27:11,743] Trial 95 finished with value: 0.6749462298266097 and parameters: {'learning_rate': 0.08, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:28:07,486] Trial 96 finished with value: 0.6789213438055536 and parameters: {'learning_rate': 0.08, 'max_bin': 160}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:29:00,496] Trial 97 finished with value: 0.6789100457678255 and parameters: {'learning_rate': 0.09, 'max_bin': 140}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:29:54,789] Trial 98 finished with value: 0.6769828390236848 and parameters: {'learning_rate': 0.12, 'max_bin': 180}. Best is trial 12 with value: 0.680736731059216.\n",
      "[I 2023-12-12 01:30:47,536] Trial 99 finished with value: 0.6766511506994761 and parameters: {'learning_rate': 0.05, 'max_bin': 110}. Best is trial 12 with value: 0.680736731059216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 991\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 989\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 989\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1312\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1311\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1307\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1309\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2304\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2302\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2300\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1415\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1416\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1413\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1312\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1311\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1307\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1309\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1415\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1416\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1413\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1312\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1311\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1307\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1309\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 991\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 989\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 989\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1415\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1416\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1413\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2304\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2302\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2300\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2304\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2302\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2300\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1312\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1311\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1307\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1309\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1415\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1416\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1413\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1203\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1627\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1824\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1821\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1819\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2207\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2206\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2021\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2016\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2014\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2013\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1922\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1917\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1725\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1415\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1416\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1414\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1413\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective_dt(trial, x_train_2,y_train_2.values.ravel()), n_trials=100,  gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf4c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(objective='multiclass',n_estimators=1000,learning_rate=0.0699999999999,max_bin=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0be00e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 41580, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610510\n",
      "[LightGBM] [Info] Start training from score -2.621700\n",
      "[LightGBM] [Info] Start training from score -0.956469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.0699999999999, max_bin=140, n_estimators=1000,\n",
       "               objective=&#x27;multiclass&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.0699999999999, max_bin=140, n_estimators=1000,\n",
       "               objective=&#x27;multiclass&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.0699999999999, max_bin=140, n_estimators=1000,\n",
       "               objective='multiclass')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_train_2,y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "500d424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610555\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1726\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621535\n",
      "[LightGBM] [Info] Start training from score -0.956516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siddh\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1726\n",
      "[LightGBM] [Info] Number of data points in the train set: 33264, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -0.610499\n",
      "[LightGBM] [Info] Start training from score -2.621949\n",
      "[LightGBM] [Info] Start training from score -0.956438\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(lgbm, x_train_2, y_train_2, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dc017c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79689755, 0.7953343 , 0.8035113 , 0.79473304, 0.8025493 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65a63137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986050986050987"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1100ce41",
   "metadata": {
    "id": "1100ce41",
    "outputId": "4a697360-deb5-46c6-faa5-98cf86e09102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train accuracy 0.925\n",
      "\n",
      " Train Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94     22581\n",
      "           1       0.94      0.75      0.83      3022\n",
      "           2       0.96      0.89      0.92     15977\n",
      "\n",
      "    accuracy                           0.92     41580\n",
      "   macro avg       0.93      0.87      0.90     41580\n",
      "weighted avg       0.93      0.92      0.92     41580\n",
      "\n",
      "\n",
      " Test accuracy 0.799\n",
      "\n",
      " Test Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      9678\n",
      "           1       0.58      0.31      0.40      1295\n",
      "           2       0.82      0.77      0.80      6847\n",
      "\n",
      "    accuracy                           0.80     17820\n",
      "   macro avg       0.73      0.65      0.68     17820\n",
      "weighted avg       0.79      0.80      0.79     17820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix(x_train_2,y_train_2,x_test_2,y_test_2,lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8893815d",
   "metadata": {
    "id": "8893815d"
   },
   "outputs": [],
   "source": [
    "Target_x=pd.read_csv(\"F:\\Personal\\Queens MMAI\\MMAI 869 – Machine Learning and AI Technology\\Driven Data team Assignment\\Test set values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4cc5b76",
   "metadata": {
    "id": "f4cc5b76",
    "outputId": "e6013a38-fc5a-467d-b61d-0faac447fc0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Dmdd</td>\n",
       "      <td>1996</td>\n",
       "      <td>DMDD</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>Dinamu Secondary School</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>1569</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>Kimnyak</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>Puma Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>Finn Water</td>\n",
       "      <td>267</td>\n",
       "      <td>FINN WATER</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>Kwa Mzee Pange</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>Bruder</td>\n",
       "      <td>1260</td>\n",
       "      <td>BRUDER</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>Kwa Mzee Turuka</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14845</th>\n",
       "      <td>39307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-24</td>\n",
       "      <td>Danida</td>\n",
       "      <td>34</td>\n",
       "      <td>Da</td>\n",
       "      <td>38.852669</td>\n",
       "      <td>-6.582841</td>\n",
       "      <td>Kwambwezi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14846</th>\n",
       "      <td>18990</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2011-03-21</td>\n",
       "      <td>Hiap</td>\n",
       "      <td>0</td>\n",
       "      <td>HIAP</td>\n",
       "      <td>37.451633</td>\n",
       "      <td>-5.350428</td>\n",
       "      <td>Bonde La Mkondoa</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>annually</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14847</th>\n",
       "      <td>28749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.739804</td>\n",
       "      <td>-4.585587</td>\n",
       "      <td>Bwawani</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>33492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>Germany</td>\n",
       "      <td>998</td>\n",
       "      <td>DWE</td>\n",
       "      <td>35.432732</td>\n",
       "      <td>-10.584159</td>\n",
       "      <td>Kwa John</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>68707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>481</td>\n",
       "      <td>Government</td>\n",
       "      <td>34.765054</td>\n",
       "      <td>-11.226012</td>\n",
       "      <td>Kwa Mzee Chagala</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14850 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "0      50785         0.0    2013-02-04                    Dmdd        1996   \n",
       "1      51630         0.0    2013-02-04  Government Of Tanzania        1569   \n",
       "2      17168         0.0    2013-02-01                     NaN        1567   \n",
       "3      45559         0.0    2013-01-22              Finn Water         267   \n",
       "4      49871       500.0    2013-03-27                  Bruder        1260   \n",
       "...      ...         ...           ...                     ...         ...   \n",
       "14845  39307         0.0    2011-02-24                  Danida          34   \n",
       "14846  18990      1000.0    2011-03-21                    Hiap           0   \n",
       "14847  28749         0.0    2013-03-04                     NaN        1476   \n",
       "14848  33492         0.0    2013-02-18                 Germany         998   \n",
       "14849  68707         0.0    2013-02-13  Government Of Tanzania         481   \n",
       "\n",
       "        installer  longitude   latitude                 wpt_name  num_private  \\\n",
       "0            DMDD  35.290799  -4.059696  Dinamu Secondary School            0   \n",
       "1             DWE  36.656709  -3.309214                  Kimnyak            0   \n",
       "2             NaN  34.767863  -5.004344           Puma Secondary            0   \n",
       "3      FINN WATER  38.058046  -9.418672           Kwa Mzee Pange            0   \n",
       "4          BRUDER  35.006123 -10.950412          Kwa Mzee Turuka            0   \n",
       "...           ...        ...        ...                      ...          ...   \n",
       "14845          Da  38.852669  -6.582841                Kwambwezi            0   \n",
       "14846        HIAP  37.451633  -5.350428         Bonde La Mkondoa            0   \n",
       "14847         NaN  34.739804  -4.585587                  Bwawani            0   \n",
       "14848         DWE  35.432732 -10.584159                 Kwa John            0   \n",
       "14849  Government  34.765054 -11.226012         Kwa Mzee Chagala            0   \n",
       "\n",
       "       ... payment_type water_quality quality_group      quantity  \\\n",
       "0      ...    never pay          soft          good      seasonal   \n",
       "1      ...    never pay          soft          good  insufficient   \n",
       "2      ...    never pay          soft          good  insufficient   \n",
       "3      ...      unknown          soft          good           dry   \n",
       "4      ...      monthly          soft          good        enough   \n",
       "...    ...          ...           ...           ...           ...   \n",
       "14845  ...    never pay          soft          good        enough   \n",
       "14846  ...     annually         salty         salty  insufficient   \n",
       "14847  ...    never pay          soft          good  insufficient   \n",
       "14848  ...    never pay          soft          good  insufficient   \n",
       "14849  ...    never pay          soft          good           dry   \n",
       "\n",
       "       quantity_group                source           source_type  \\\n",
       "0            seasonal  rainwater harvesting  rainwater harvesting   \n",
       "1        insufficient                spring                spring   \n",
       "2        insufficient  rainwater harvesting  rainwater harvesting   \n",
       "3                 dry          shallow well          shallow well   \n",
       "4              enough                spring                spring   \n",
       "...               ...                   ...                   ...   \n",
       "14845          enough                 river            river/lake   \n",
       "14846    insufficient          shallow well          shallow well   \n",
       "14847    insufficient                   dam                   dam   \n",
       "14848    insufficient                 river            river/lake   \n",
       "14849             dry                spring                spring   \n",
       "\n",
       "       source_class     waterpoint_type waterpoint_type_group  \n",
       "0           surface               other                 other  \n",
       "1       groundwater  communal standpipe    communal standpipe  \n",
       "2           surface               other                 other  \n",
       "3       groundwater               other                 other  \n",
       "4       groundwater  communal standpipe    communal standpipe  \n",
       "...             ...                 ...                   ...  \n",
       "14845       surface  communal standpipe    communal standpipe  \n",
       "14846   groundwater           hand pump             hand pump  \n",
       "14847       surface  communal standpipe    communal standpipe  \n",
       "14848       surface  communal standpipe    communal standpipe  \n",
       "14849   groundwater  communal standpipe    communal standpipe  \n",
       "\n",
       "[14850 rows x 40 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62e887a0",
   "metadata": {
    "id": "62e887a0"
   },
   "outputs": [],
   "source": [
    "Target1=Target_x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82b8e5e2",
   "metadata": {
    "id": "82b8e5e2"
   },
   "outputs": [],
   "source": [
    "def process_target2(a):\n",
    "    ## new feature processing\n",
    "    for i in [\"funder\",\"installer\"]:\n",
    "        a[i]=a[i].str.lower()\n",
    "        minor_values=a[i].value_counts(dropna=False)[a[i].value_counts(dropna=False,normalize=True).cumsum().values>0.95].index\n",
    "        a[i]=a[i].apply(lambda s:\"minor\" if s in minor_values else s)\n",
    "        grp_mode=a.groupby(by=[\"region\"])[i].transform(lambda x: x.mode().iloc[0])\n",
    "        a[i]=a[i].fillna(grp_mode)\n",
    "    a[\"long_mod\"]=a[\"longitude\"]\n",
    "    a.loc[a['long_mod'] == 0, 'long_mod'] = pd.NA\n",
    "    grp_means=a.groupby(by=[\"region\"])[\"long_mod\"].transform(\"mean\")\n",
    "    a.long_mod=a.long_mod.fillna(grp_means)\n",
    "    a[\"lat_mod\"]=a[\"latitude\"]\n",
    "    a.loc[a['lat_mod'] <-100, 'lat_mod'] = pd.NA\n",
    "    grp_means2=a.groupby(by=[\"region\"])[\"lat_mod\"].transform(\"mean\")\n",
    "    a.lat_mod=a.lat_mod.fillna(grp_means2)\n",
    "    a[\"gps_height_mod\"]=a[\"gps_height\"]\n",
    "    a.loc[a['gps_height_mod'] == 0, 'gps_height_mod'] = pd.NA\n",
    "    grp_means3=a.groupby(by=[\"basin\"])[\"gps_height_mod\"].transform(\"mean\")\n",
    "    a.gps_height_mod=a.gps_height_mod.fillna(grp_means3)\n",
    "    a.wpt_name=a.wpt_name.str.lower()\n",
    "    x=list(a.wpt_name.value_counts()[(a.wpt_name.value_counts().values==1)].index)\n",
    "    a.wpt_name=a.wpt_name.replace(x,\"single\")\n",
    "    #subvillage\n",
    "    grp_mode4=a.groupby(by=[\"region\"])[\"subvillage\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.subvillage=a.subvillage.fillna(grp_mode4)\n",
    "    y=list(a.subvillage.value_counts()[(a.subvillage.value_counts().values==1)].index)\n",
    "    a.subvillage=a.subvillage.replace(y,\"single\")\n",
    "    a.public_meeting=a.public_meeting.fillna(\"True\")\n",
    "    grp_mode5=a.groupby(by=[\"region\"])[\"permit\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.permit=a.permit.fillna(grp_mode5)\n",
    "    grp_mode6=a.groupby(by=[\"region\"])[\"scheme_management\"].transform(lambda x: x.mode().iloc[0])\n",
    "    a.scheme_management=a.scheme_management.fillna(grp_mode6)\n",
    "    a[\"permit\"]=a[\"permit\"].map(lambda s: \"T\" if s==True else(\"F\" if s== False else \"M\"))\n",
    "    a[\"public_meeting\"]=a[\"public_meeting\"].map(lambda s: \"T\" if s==True else(\"F\" if s== False else \"M\"))\n",
    "    #bin_edges=[np.min(a.gps_height)-1,0,500,1000,1500,2000,np.max(a.gps_height)]\n",
    "    #bin_labels=[\"<0\",\"0-500\",\"500-1000\",\"1000-1500\",\"1500-2000\",\">2000\"]\n",
    "    #a[\"gps_height_cat\"]=pd.cut(a.gps_height,bins=bin_edges,labels=bin_labels).astype(\"O\")\n",
    "    a=a.drop([\"id\",\"recorded_by\",\"scheme_name\",\"num_private\"],axis=1)\n",
    "    a[\"amount_tsh_cat\"] = a[\"amount_tsh\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "    date_format = '%Y-%m-%d'\n",
    "    a[\"date_recorded\"]=pd.to_datetime(a[\"date_recorded\"])\n",
    "    a[\"dsr\"]=pd.to_datetime(\"2023-11-16\")-a[\"date_recorded\"]\n",
    "    a.dsr=(a.dsr/ pd.Timedelta(seconds=86400))\n",
    "    bin_edges=[np.min(a.construction_year)-1,0,1961,1971,1981,1991,2001,np.max(a.construction_year)+1]\n",
    "    bin_labels=[\"0\",\"0-1960\",\"1960-70\",\"1970-80\",\"1980-90\",\"1990-2000\",\"2001-2013\"]\n",
    "    a[\"construction_year_cat\"]=pd.cut(a.construction_year,bins=bin_edges,labels=bin_labels).astype(\"O\")\n",
    "    a=a.drop([\"amount_tsh\",\"date_recorded\",\"gps_height\",\"latitude\",\"longitude\",\"construction_year\"],axis=1)\n",
    "    a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]]=a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]].astype(\"O\")\n",
    "    cat=a.select_dtypes(include=\"O\").columns\n",
    "    #a[cat] = a[cat].fillna('missing')\n",
    "    a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]]=a[[\"region_code\",\"district_code\",\"amount_tsh_cat\"]].astype(\"O\")\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6e07fba",
   "metadata": {
    "id": "a6e07fba"
   },
   "outputs": [],
   "source": [
    "Target1=process_target2(Target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6889236a",
   "metadata": {
    "id": "6889236a",
    "outputId": "5fcf82ca-1522-44c2-8249-9b388e027fbd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>...</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>long_mod</th>\n",
       "      <th>lat_mod</th>\n",
       "      <th>gps_height_mod</th>\n",
       "      <th>amount_tsh_cat</th>\n",
       "      <th>dsr</th>\n",
       "      <th>construction_year_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dmdd</td>\n",
       "      <td>dmdd</td>\n",
       "      <td>single</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Magoma</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>Mbulu</td>\n",
       "      <td>Bashay</td>\n",
       "      <td>...</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>1996.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3937.0</td>\n",
       "      <td>2001-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>government of tanzania</td>\n",
       "      <td>dwe</td>\n",
       "      <td>single</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>single</td>\n",
       "      <td>Arusha</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Arusha Rural</td>\n",
       "      <td>Kimnyaki</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>1569.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3937.0</td>\n",
       "      <td>1990-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcrs</td>\n",
       "      <td>sema</td>\n",
       "      <td>single</td>\n",
       "      <td>Internal</td>\n",
       "      <td>single</td>\n",
       "      <td>Singida</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Singida Rural</td>\n",
       "      <td>Puma</td>\n",
       "      <td>...</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>1567.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3940.0</td>\n",
       "      <td>2001-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finn water</td>\n",
       "      <td>finn water</td>\n",
       "      <td>single</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Kipindimbi</td>\n",
       "      <td>Lindi</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>Liwale</td>\n",
       "      <td>Mkutano</td>\n",
       "      <td>...</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>267.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>1980-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bruder</td>\n",
       "      <td>bruder</td>\n",
       "      <td>single</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Losonga</td>\n",
       "      <td>Ruvuma</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Mbinga</td>\n",
       "      <td>Mbinga Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>1260.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>3886.0</td>\n",
       "      <td>1990-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14845</th>\n",
       "      <td>danida</td>\n",
       "      <td>da</td>\n",
       "      <td>single</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>Yombo</td>\n",
       "      <td>Pwani</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Bagamoyo</td>\n",
       "      <td>Yombo</td>\n",
       "      <td>...</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>38.852669</td>\n",
       "      <td>-6.582841</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4648.0</td>\n",
       "      <td>1980-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14846</th>\n",
       "      <td>hiap</td>\n",
       "      <td>hiap</td>\n",
       "      <td>single</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Mkondoa</td>\n",
       "      <td>Tanga</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Kilindi</td>\n",
       "      <td>Mvungwe</td>\n",
       "      <td>...</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>37.451633</td>\n",
       "      <td>-5.350428</td>\n",
       "      <td>1082.02754</td>\n",
       "      <td>1</td>\n",
       "      <td>4623.0</td>\n",
       "      <td>1990-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14847</th>\n",
       "      <td>tcrs</td>\n",
       "      <td>sema</td>\n",
       "      <td>bwawani</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Juhudi</td>\n",
       "      <td>Singida</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Singida Rural</td>\n",
       "      <td>Ughandi</td>\n",
       "      <td>...</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.739804</td>\n",
       "      <td>-4.585587</td>\n",
       "      <td>1476.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>2001-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>germany</td>\n",
       "      <td>dwe</td>\n",
       "      <td>kwa john</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Namakinga B</td>\n",
       "      <td>Ruvuma</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Songea Rural</td>\n",
       "      <td>Maposeni</td>\n",
       "      <td>...</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>35.432732</td>\n",
       "      <td>-10.584159</td>\n",
       "      <td>998.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3923.0</td>\n",
       "      <td>2001-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>government of tanzania</td>\n",
       "      <td>government</td>\n",
       "      <td>single</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>single</td>\n",
       "      <td>Ruvuma</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Mbinga</td>\n",
       "      <td>Mbamba bay</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>34.765054</td>\n",
       "      <td>-11.226012</td>\n",
       "      <td>481.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>2001-2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14850 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       funder   installer  wpt_name                    basin  \\\n",
       "0                        dmdd        dmdd    single                 Internal   \n",
       "1      government of tanzania         dwe    single                  Pangani   \n",
       "2                        tcrs        sema    single                 Internal   \n",
       "3                  finn water  finn water    single  Ruvuma / Southern Coast   \n",
       "4                      bruder      bruder    single  Ruvuma / Southern Coast   \n",
       "...                       ...         ...       ...                      ...   \n",
       "14845                  danida          da    single              Wami / Ruvu   \n",
       "14846                    hiap        hiap    single                  Pangani   \n",
       "14847                    tcrs        sema   bwawani                 Internal   \n",
       "14848                 germany         dwe  kwa john               Lake Nyasa   \n",
       "14849  government of tanzania  government    single               Lake Nyasa   \n",
       "\n",
       "        subvillage   region region_code district_code            lga  \\\n",
       "0           Magoma  Manyara          21             3          Mbulu   \n",
       "1           single   Arusha           2             2   Arusha Rural   \n",
       "2           single  Singida          13             2  Singida Rural   \n",
       "3       Kipindimbi    Lindi          80            43         Liwale   \n",
       "4          Losonga   Ruvuma          10             3         Mbinga   \n",
       "...            ...      ...         ...           ...            ...   \n",
       "14845        Yombo    Pwani           6             1       Bagamoyo   \n",
       "14846      Mkondoa    Tanga           4             7        Kilindi   \n",
       "14847       Juhudi  Singida          13             2  Singida Rural   \n",
       "14848  Namakinga B   Ruvuma          10             2   Songea Rural   \n",
       "14849       single   Ruvuma          10             3         Mbinga   \n",
       "\n",
       "               ward  ...           source_type source_class  \\\n",
       "0            Bashay  ...  rainwater harvesting      surface   \n",
       "1          Kimnyaki  ...                spring  groundwater   \n",
       "2              Puma  ...  rainwater harvesting      surface   \n",
       "3           Mkutano  ...          shallow well  groundwater   \n",
       "4      Mbinga Urban  ...                spring  groundwater   \n",
       "...             ...  ...                   ...          ...   \n",
       "14845         Yombo  ...            river/lake      surface   \n",
       "14846       Mvungwe  ...          shallow well  groundwater   \n",
       "14847       Ughandi  ...                   dam      surface   \n",
       "14848      Maposeni  ...            river/lake      surface   \n",
       "14849    Mbamba bay  ...                spring  groundwater   \n",
       "\n",
       "          waterpoint_type waterpoint_type_group   long_mod    lat_mod  \\\n",
       "0                   other                 other  35.290799  -4.059696   \n",
       "1      communal standpipe    communal standpipe  36.656709  -3.309214   \n",
       "2                   other                 other  34.767863  -5.004344   \n",
       "3                   other                 other  38.058046  -9.418672   \n",
       "4      communal standpipe    communal standpipe  35.006123 -10.950412   \n",
       "...                   ...                   ...        ...        ...   \n",
       "14845  communal standpipe    communal standpipe  38.852669  -6.582841   \n",
       "14846           hand pump             hand pump  37.451633  -5.350428   \n",
       "14847  communal standpipe    communal standpipe  34.739804  -4.585587   \n",
       "14848  communal standpipe    communal standpipe  35.432732 -10.584159   \n",
       "14849  communal standpipe    communal standpipe  34.765054 -11.226012   \n",
       "\n",
       "      gps_height_mod amount_tsh_cat     dsr construction_year_cat  \n",
       "0         1996.00000              0  3937.0             2001-2013  \n",
       "1         1569.00000              0  3937.0             1990-2000  \n",
       "2         1567.00000              0  3940.0             2001-2013  \n",
       "3          267.00000              0  3950.0               1980-90  \n",
       "4         1260.00000              1  3886.0             1990-2000  \n",
       "...              ...            ...     ...                   ...  \n",
       "14845       34.00000              0  4648.0               1980-90  \n",
       "14846     1082.02754              1  4623.0             1990-2000  \n",
       "14847     1476.00000              0  3909.0             2001-2013  \n",
       "14848      998.00000              0  3923.0             2001-2013  \n",
       "14849      481.00000              0  3928.0             2001-2013  \n",
       "\n",
       "[14850 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7f059ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target1[Label_col]=Or.transform(Target1[Label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4336f26",
   "metadata": {
    "id": "a4336f26"
   },
   "outputs": [],
   "source": [
    "y_pred=lgbm.predict(Target1)\n",
    "y_pred=le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bc7425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred, columns=[\"status_group\"])\n",
    "y_pred[\"id\"]=Target_x[\"id\"]\n",
    "y_pred=y_pred.reindex([\"id\",\"status_group\"],axis=1)\n",
    "y_pred.to_csv(\"F:/Personal/Queens MMAI/MMAI 869 – Machine Learning and AI Technology/Driven Data team Assignment/LGBM 12.12.2023.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea59e7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
